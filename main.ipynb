{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "def return_iters():\n",
    "    from ast import literal_eval as make_tuple\n",
    "    global db\n",
    "    train_iter=[]\n",
    "    test_iter=[]\n",
    "    file = open(db,'r')\n",
    "    # file2 = open(\"PoliticalCompassML/databaseTop.txt\",'r')\n",
    "    mapping = {\n",
    "    \"Libertarian Left\":1,\n",
    "    \"Libertarian Right\":2,\n",
    "    \"Authoritarian Left\":3,\n",
    "    \"Authoritarian Right\":4,\n",
    "    }\n",
    "    for line in file:\n",
    "        opinion, text = make_tuple(line)\n",
    "        train_iter+=[(mapping[opinion],text)]\n",
    "        test_iter+=[(mapping[opinion],text)]\n",
    "    # for line in file2:\n",
    "    #     opinion, text = make_tuple(line)\n",
    "    #     train_iter+=[(mapping[opinion],text)]\n",
    "    #     test_iter+=[(mapping[opinion],text)]\n",
    "    train_iter=iter(train_iter)\n",
    "    test_iter=iter(test_iter)\n",
    "    file.close()\n",
    "    # file2.close()\n",
    "    return train_iter,test_iter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1\n",
    "train_iter,test_iter= return_iters()\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "         label_list.append(label_pipeline(_label))\n",
    "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "         text_list.append(processed_text)\n",
    "         offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "train_iter,test_iter= return_iters()\n",
    "\n",
    "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        # self.fc = nn.Linear(embed_dim, num_class)\n",
    "        # self.fc = nn.SELU()\n",
    "        self.fc = nn.ReLU()\n",
    "        # self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "train_iter,test_iter= return_iters()\n",
    "\n",
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "# print(train_iter)\n",
    "# print([label for (label, text) in train_iter])\n",
    "print(num_class)\n",
    "vocab_size = len(vocab)\n",
    "emsize = 128\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 50\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text, offsets)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |    50/  644 batches | accuracy    0.359\n",
      "| epoch   1 |   100/  644 batches | accuracy    0.360\n",
      "| epoch   1 |   150/  644 batches | accuracy    0.361\n",
      "| epoch   1 |   200/  644 batches | accuracy    0.335\n",
      "| epoch   1 |   250/  644 batches | accuracy    0.331\n",
      "| epoch   1 |   300/  644 batches | accuracy    0.339\n",
      "| epoch   1 |   350/  644 batches | accuracy    0.361\n",
      "| epoch   1 |   400/  644 batches | accuracy    0.346\n",
      "| epoch   1 |   450/  644 batches | accuracy    0.347\n",
      "| epoch   1 |   500/  644 batches | accuracy    0.354\n",
      "| epoch   1 |   550/  644 batches | accuracy    0.338\n",
      "| epoch   1 |   600/  644 batches | accuracy    0.354\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  2.94s | valid accuracy    0.353 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |    50/  644 batches | accuracy    0.332\n",
      "| epoch   2 |   100/  644 batches | accuracy    0.361\n",
      "| epoch   2 |   150/  644 batches | accuracy    0.341\n",
      "| epoch   2 |   200/  644 batches | accuracy    0.361\n",
      "| epoch   2 |   250/  644 batches | accuracy    0.348\n",
      "| epoch   2 |   300/  644 batches | accuracy    0.372\n",
      "| epoch   2 |   350/  644 batches | accuracy    0.356\n",
      "| epoch   2 |   400/  644 batches | accuracy    0.343\n",
      "| epoch   2 |   450/  644 batches | accuracy    0.357\n",
      "| epoch   2 |   500/  644 batches | accuracy    0.334\n",
      "| epoch   2 |   550/  644 batches | accuracy    0.378\n",
      "| epoch   2 |   600/  644 batches | accuracy    0.351\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  2.26s | valid accuracy    0.361 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |    50/  644 batches | accuracy    0.357\n",
      "| epoch   3 |   100/  644 batches | accuracy    0.337\n",
      "| epoch   3 |   150/  644 batches | accuracy    0.368\n",
      "| epoch   3 |   200/  644 batches | accuracy    0.355\n",
      "| epoch   3 |   250/  644 batches | accuracy    0.362\n",
      "| epoch   3 |   300/  644 batches | accuracy    0.363\n",
      "| epoch   3 |   350/  644 batches | accuracy    0.365\n",
      "| epoch   3 |   400/  644 batches | accuracy    0.350\n",
      "| epoch   3 |   450/  644 batches | accuracy    0.358\n",
      "| epoch   3 |   500/  644 batches | accuracy    0.354\n",
      "| epoch   3 |   550/  644 batches | accuracy    0.365\n",
      "| epoch   3 |   600/  644 batches | accuracy    0.345\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  2.16s | valid accuracy    0.364 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |    50/  644 batches | accuracy    0.372\n",
      "| epoch   4 |   100/  644 batches | accuracy    0.354\n",
      "| epoch   4 |   150/  644 batches | accuracy    0.342\n",
      "| epoch   4 |   200/  644 batches | accuracy    0.372\n",
      "| epoch   4 |   250/  644 batches | accuracy    0.331\n",
      "| epoch   4 |   300/  644 batches | accuracy    0.361\n",
      "| epoch   4 |   350/  644 batches | accuracy    0.351\n",
      "| epoch   4 |   400/  644 batches | accuracy    0.351\n",
      "| epoch   4 |   450/  644 batches | accuracy    0.366\n",
      "| epoch   4 |   500/  644 batches | accuracy    0.378\n",
      "| epoch   4 |   550/  644 batches | accuracy    0.346\n",
      "| epoch   4 |   600/  644 batches | accuracy    0.341\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time:  2.10s | valid accuracy    0.363 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |    50/  644 batches | accuracy    0.363\n",
      "| epoch   5 |   100/  644 batches | accuracy    0.369\n",
      "| epoch   5 |   150/  644 batches | accuracy    0.364\n",
      "| epoch   5 |   200/  644 batches | accuracy    0.372\n",
      "| epoch   5 |   250/  644 batches | accuracy    0.356\n",
      "| epoch   5 |   300/  644 batches | accuracy    0.341\n",
      "| epoch   5 |   350/  644 batches | accuracy    0.343\n",
      "| epoch   5 |   400/  644 batches | accuracy    0.343\n",
      "| epoch   5 |   450/  644 batches | accuracy    0.352\n",
      "| epoch   5 |   500/  644 batches | accuracy    0.367\n",
      "| epoch   5 |   550/  644 batches | accuracy    0.351\n",
      "| epoch   5 |   600/  644 batches | accuracy    0.356\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time:  2.13s | valid accuracy    0.363 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |    50/  644 batches | accuracy    0.348\n",
      "| epoch   6 |   100/  644 batches | accuracy    0.358\n",
      "| epoch   6 |   150/  644 batches | accuracy    0.366\n",
      "| epoch   6 |   200/  644 batches | accuracy    0.366\n",
      "| epoch   6 |   250/  644 batches | accuracy    0.372\n",
      "| epoch   6 |   300/  644 batches | accuracy    0.359\n",
      "| epoch   6 |   350/  644 batches | accuracy    0.352\n",
      "| epoch   6 |   400/  644 batches | accuracy    0.347\n",
      "| epoch   6 |   450/  644 batches | accuracy    0.351\n",
      "| epoch   6 |   500/  644 batches | accuracy    0.341\n",
      "| epoch   6 |   550/  644 batches | accuracy    0.357\n",
      "| epoch   6 |   600/  644 batches | accuracy    0.357\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time:  2.21s | valid accuracy    0.363 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |    50/  644 batches | accuracy    0.357\n",
      "| epoch   7 |   100/  644 batches | accuracy    0.362\n",
      "| epoch   7 |   150/  644 batches | accuracy    0.343\n",
      "| epoch   7 |   200/  644 batches | accuracy    0.345\n",
      "| epoch   7 |   250/  644 batches | accuracy    0.343\n",
      "| epoch   7 |   300/  644 batches | accuracy    0.361\n",
      "| epoch   7 |   350/  644 batches | accuracy    0.369\n",
      "| epoch   7 |   400/  644 batches | accuracy    0.381\n",
      "| epoch   7 |   450/  644 batches | accuracy    0.365\n",
      "| epoch   7 |   500/  644 batches | accuracy    0.362\n",
      "| epoch   7 |   550/  644 batches | accuracy    0.352\n",
      "| epoch   7 |   600/  644 batches | accuracy    0.354\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time:  2.19s | valid accuracy    0.363 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |    50/  644 batches | accuracy    0.347\n",
      "| epoch   8 |   100/  644 batches | accuracy    0.354\n",
      "| epoch   8 |   150/  644 batches | accuracy    0.359\n",
      "| epoch   8 |   200/  644 batches | accuracy    0.356\n",
      "| epoch   8 |   250/  644 batches | accuracy    0.356\n",
      "| epoch   8 |   300/  644 batches | accuracy    0.367\n",
      "| epoch   8 |   350/  644 batches | accuracy    0.350\n",
      "| epoch   8 |   400/  644 batches | accuracy    0.371\n",
      "| epoch   8 |   450/  644 batches | accuracy    0.357\n",
      "| epoch   8 |   500/  644 batches | accuracy    0.349\n",
      "| epoch   8 |   550/  644 batches | accuracy    0.341\n",
      "| epoch   8 |   600/  644 batches | accuracy    0.349\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time:  2.11s | valid accuracy    0.363 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |    50/  644 batches | accuracy    0.365\n",
      "| epoch   9 |   100/  644 batches | accuracy    0.352\n",
      "| epoch   9 |   150/  644 batches | accuracy    0.341\n",
      "| epoch   9 |   200/  644 batches | accuracy    0.336\n",
      "| epoch   9 |   250/  644 batches | accuracy    0.347\n",
      "| epoch   9 |   300/  644 batches | accuracy    0.357\n",
      "| epoch   9 |   350/  644 batches | accuracy    0.353\n",
      "| epoch   9 |   400/  644 batches | accuracy    0.364\n",
      "| epoch   9 |   450/  644 batches | accuracy    0.367\n",
      "| epoch   9 |   500/  644 batches | accuracy    0.359\n",
      "| epoch   9 |   550/  644 batches | accuracy    0.354\n",
      "| epoch   9 |   600/  644 batches | accuracy    0.369\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time:  2.12s | valid accuracy    0.363 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |    50/  644 batches | accuracy    0.339\n",
      "| epoch  10 |   100/  644 batches | accuracy    0.352\n",
      "| epoch  10 |   150/  644 batches | accuracy    0.340\n",
      "| epoch  10 |   200/  644 batches | accuracy    0.357\n",
      "| epoch  10 |   250/  644 batches | accuracy    0.369\n",
      "| epoch  10 |   300/  644 batches | accuracy    0.347\n",
      "| epoch  10 |   350/  644 batches | accuracy    0.367\n",
      "| epoch  10 |   400/  644 batches | accuracy    0.359\n",
      "| epoch  10 |   450/  644 batches | accuracy    0.358\n",
      "| epoch  10 |   500/  644 batches | accuracy    0.364\n",
      "| epoch  10 |   550/  644 batches | accuracy    0.380\n",
      "| epoch  10 |   600/  644 batches | accuracy    0.344\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time:  2.30s | valid accuracy    0.363 \n",
      "-----------------------------------------------------------\n",
      "| epoch  11 |    50/  644 batches | accuracy    0.369\n",
      "| epoch  11 |   100/  644 batches | accuracy    0.348\n",
      "| epoch  11 |   150/  644 batches | accuracy    0.359\n",
      "| epoch  11 |   200/  644 batches | accuracy    0.357\n",
      "| epoch  11 |   250/  644 batches | accuracy    0.339\n",
      "| epoch  11 |   300/  644 batches | accuracy    0.346\n",
      "| epoch  11 |   350/  644 batches | accuracy    0.362\n",
      "| epoch  11 |   400/  644 batches | accuracy    0.344\n",
      "| epoch  11 |   450/  644 batches | accuracy    0.351\n",
      "| epoch  11 |   500/  644 batches | accuracy    0.385\n",
      "| epoch  11 |   550/  644 batches | accuracy    0.366\n",
      "| epoch  11 |   600/  644 batches | accuracy    0.351\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  11 | time:  2.21s | valid accuracy    0.363 \n",
      "-----------------------------------------------------------\n",
      "| epoch  12 |    50/  644 batches | accuracy    0.350\n",
      "| epoch  12 |   100/  644 batches | accuracy    0.353\n",
      "| epoch  12 |   150/  644 batches | accuracy    0.374\n",
      "| epoch  12 |   200/  644 batches | accuracy    0.352\n",
      "| epoch  12 |   250/  644 batches | accuracy    0.366\n",
      "| epoch  12 |   300/  644 batches | accuracy    0.354\n",
      "| epoch  12 |   350/  644 batches | accuracy    0.360\n",
      "| epoch  12 |   400/  644 batches | accuracy    0.340\n",
      "| epoch  12 |   450/  644 batches | accuracy    0.348\n",
      "| epoch  12 |   500/  644 batches | accuracy    0.367\n",
      "| epoch  12 |   550/  644 batches | accuracy    0.354\n",
      "| epoch  12 |   600/  644 batches | accuracy    0.362\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  12 | time:  2.26s | valid accuracy    0.363 \n",
      "-----------------------------------------------------------\n",
      "| epoch  13 |    50/  644 batches | accuracy    0.339\n",
      "| epoch  13 |   100/  644 batches | accuracy    0.357\n",
      "| epoch  13 |   150/  644 batches | accuracy    0.347\n",
      "| epoch  13 |   200/  644 batches | accuracy    0.347\n",
      "| epoch  13 |   250/  644 batches | accuracy    0.359\n",
      "| epoch  13 |   300/  644 batches | accuracy    0.365\n",
      "| epoch  13 |   350/  644 batches | accuracy    0.371\n",
      "| epoch  13 |   400/  644 batches | accuracy    0.353\n",
      "| epoch  13 |   450/  644 batches | accuracy    0.356\n",
      "| epoch  13 |   500/  644 batches | accuracy    0.364\n",
      "| epoch  13 |   550/  644 batches | accuracy    0.349\n",
      "| epoch  13 |   600/  644 batches | accuracy    0.369\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  13 | time:  2.21s | valid accuracy    0.363 \n",
      "-----------------------------------------------------------\n",
      "| epoch  14 |    50/  644 batches | accuracy    0.347\n",
      "| epoch  14 |   100/  644 batches | accuracy    0.362\n",
      "| epoch  14 |   150/  644 batches | accuracy    0.340\n",
      "| epoch  14 |   200/  644 batches | accuracy    0.359\n",
      "| epoch  14 |   250/  644 batches | accuracy    0.359\n",
      "| epoch  14 |   300/  644 batches | accuracy    0.352\n",
      "| epoch  14 |   350/  644 batches | accuracy    0.363\n",
      "| epoch  14 |   400/  644 batches | accuracy    0.363\n",
      "| epoch  14 |   450/  644 batches | accuracy    0.364\n",
      "| epoch  14 |   500/  644 batches | accuracy    0.349\n",
      "| epoch  14 |   550/  644 batches | accuracy    0.377\n",
      "| epoch  14 |   600/  644 batches | accuracy    0.334\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  14 | time:  2.06s | valid accuracy    0.363 \n",
      "-----------------------------------------------------------\n",
      "| epoch  15 |    50/  644 batches | accuracy    0.361\n",
      "| epoch  15 |   100/  644 batches | accuracy    0.349\n",
      "| epoch  15 |   150/  644 batches | accuracy    0.344\n",
      "| epoch  15 |   200/  644 batches | accuracy    0.353\n",
      "| epoch  15 |   250/  644 batches | accuracy    0.371\n",
      "| epoch  15 |   300/  644 batches | accuracy    0.352\n",
      "| epoch  15 |   350/  644 batches | accuracy    0.352\n",
      "| epoch  15 |   400/  644 batches | accuracy    0.347\n",
      "| epoch  15 |   450/  644 batches | accuracy    0.385\n",
      "| epoch  15 |   500/  644 batches | accuracy    0.346\n",
      "| epoch  15 |   550/  644 batches | accuracy    0.359\n",
      "| epoch  15 |   600/  644 batches | accuracy    0.355\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  15 | time:  2.10s | valid accuracy    0.363 \n",
      "-----------------------------------------------------------\n",
      "| epoch  16 |    50/  644 batches | accuracy    0.352\n",
      "| epoch  16 |   100/  644 batches | accuracy    0.361\n",
      "| epoch  16 |   150/  644 batches | accuracy    0.343\n",
      "| epoch  16 |   200/  644 batches | accuracy    0.356\n",
      "| epoch  16 |   250/  644 batches | accuracy    0.347\n",
      "| epoch  16 |   300/  644 batches | accuracy    0.371\n",
      "| epoch  16 |   350/  644 batches | accuracy    0.340\n",
      "| epoch  16 |   400/  644 batches | accuracy    0.343\n",
      "| epoch  16 |   450/  644 batches | accuracy    0.364\n",
      "| epoch  16 |   500/  644 batches | accuracy    0.381\n",
      "| epoch  16 |   550/  644 batches | accuracy    0.358\n",
      "| epoch  16 |   600/  644 batches | accuracy    0.357\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  16 | time:  2.09s | valid accuracy    0.363 \n",
      "-----------------------------------------------------------\n",
      "| epoch  17 |    50/  644 batches | accuracy    0.358\n",
      "| epoch  17 |   100/  644 batches | accuracy    0.367\n",
      "| epoch  17 |   150/  644 batches | accuracy    0.376\n",
      "| epoch  17 |   200/  644 batches | accuracy    0.359\n",
      "| epoch  17 |   250/  644 batches | accuracy    0.362\n",
      "| epoch  17 |   300/  644 batches | accuracy    0.352\n",
      "| epoch  17 |   350/  644 batches | accuracy    0.355\n",
      "| epoch  17 |   400/  644 batches | accuracy    0.350\n",
      "| epoch  17 |   450/  644 batches | accuracy    0.355\n",
      "| epoch  17 |   500/  644 batches | accuracy    0.360\n",
      "| epoch  17 |   550/  644 batches | accuracy    0.349\n",
      "| epoch  17 |   600/  644 batches | accuracy    0.352\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  17 | time:  2.20s | valid accuracy    0.363 \n",
      "-----------------------------------------------------------\n",
      "| epoch  18 |    50/  644 batches | accuracy    0.376\n",
      "| epoch  18 |   100/  644 batches | accuracy    0.370\n",
      "| epoch  18 |   150/  644 batches | accuracy    0.351\n",
      "| epoch  18 |   200/  644 batches | accuracy    0.346\n",
      "| epoch  18 |   250/  644 batches | accuracy    0.332\n",
      "| epoch  18 |   300/  644 batches | accuracy    0.343\n",
      "| epoch  18 |   350/  644 batches | accuracy    0.361\n",
      "| epoch  18 |   400/  644 batches | accuracy    0.338\n",
      "| epoch  18 |   450/  644 batches | accuracy    0.349\n",
      "| epoch  18 |   500/  644 batches | accuracy    0.379\n",
      "| epoch  18 |   550/  644 batches | accuracy    0.360\n",
      "| epoch  18 |   600/  644 batches | accuracy    0.364\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  18 | time:  2.37s | valid accuracy    0.363 \n",
      "-----------------------------------------------------------\n",
      "| epoch  19 |    50/  644 batches | accuracy    0.379\n",
      "| epoch  19 |   100/  644 batches | accuracy    0.343\n",
      "| epoch  19 |   150/  644 batches | accuracy    0.349\n",
      "| epoch  19 |   200/  644 batches | accuracy    0.378\n",
      "| epoch  19 |   250/  644 batches | accuracy    0.369\n",
      "| epoch  19 |   300/  644 batches | accuracy    0.345\n",
      "| epoch  19 |   350/  644 batches | accuracy    0.350\n",
      "| epoch  19 |   400/  644 batches | accuracy    0.372\n",
      "| epoch  19 |   450/  644 batches | accuracy    0.351\n",
      "| epoch  19 |   500/  644 batches | accuracy    0.354\n",
      "| epoch  19 |   550/  644 batches | accuracy    0.333\n",
      "| epoch  19 |   600/  644 batches | accuracy    0.357\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  19 | time:  2.30s | valid accuracy    0.363 \n",
      "-----------------------------------------------------------\n",
      "| epoch  20 |    50/  644 batches | accuracy    0.361\n",
      "| epoch  20 |   100/  644 batches | accuracy    0.353\n",
      "| epoch  20 |   150/  644 batches | accuracy    0.371\n",
      "| epoch  20 |   200/  644 batches | accuracy    0.356\n",
      "| epoch  20 |   250/  644 batches | accuracy    0.348\n",
      "| epoch  20 |   300/  644 batches | accuracy    0.344\n",
      "| epoch  20 |   350/  644 batches | accuracy    0.347\n",
      "| epoch  20 |   400/  644 batches | accuracy    0.367\n",
      "| epoch  20 |   450/  644 batches | accuracy    0.339\n",
      "| epoch  20 |   500/  644 batches | accuracy    0.361\n",
      "| epoch  20 |   550/  644 batches | accuracy    0.354\n",
      "| epoch  20 |   600/  644 batches | accuracy    0.358\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  20 | time:  2.26s | valid accuracy    0.363 \n",
      "-----------------------------------------------------------\n",
      "test accuracy    0.357\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "import tensorflow as tf\n",
    "# Hyperparameters\n",
    "global db\n",
    "db = \"Merged_No_Dupes_DB\"\n",
    "EPOCHS = 20 # epoch\n",
    "LR = 0.15 # learning rate\n",
    "BATCH_SIZE = 32 # batch size for training\n",
    "run_ledger= open(\"Run_Ledger.txt\",'a')\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "# optimizer = torch.optim.Adam(model.parameters(),lr=0.005,betas=(0.9,0.999),eps=1e-08,weight_decay=0,amsgrad=False)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "train_iter,test_iter= return_iters()\n",
    "\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "first_flag = True\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "      scheduler.step()\n",
    "    else:\n",
    "       total_accu = accu_val\n",
    "    if first_flag:\n",
    "        run_ledger.write(\"Database file: \"+db+\"\\t\"+\"Epochs:\" +str(EPOCHS)+\"\\t\"+\"LR: \"+str(LR)+\"\\t\"+\"Batch Size: \"+str(BATCH_SIZE)+\"\\tinit accu_val:\"+str(accu_val)+\"\\n\")\n",
    "        first_flag=False\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)\n",
    "run_ledger.write(\"Final accu:\\t\"+str(accu_val)+\"\\n\\n\")\n",
    "accu_test = evaluate(test_dataloader)\n",
    "out = 'test accuracy {:8.3f}'.format(accu_test)\n",
    "function=\"relu\"\n",
    "print(out)\n",
    "run_ledger.write(out+\"function:\"+function+'\\n')\n",
    "run_ledger.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Libertarian Right comment\n"
     ]
    }
   ],
   "source": [
    "mapping = {\n",
    "1:\"Libertarian Left\",\n",
    "2:\"Libertarian Right\",\n",
    "3:\"Authoritarian Left\",\n",
    "4:\"Authoritarian Right\",\n",
    "}\n",
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item() + 1\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "ex_text_str = \"\"\"\n",
    "The rise of the two income household is one of the big reasons nobody likes to talk about. Once it became normal for women to be in the workforce while also raising kids, housing prices reflected the new higher median household income. Two incomes used to be a luxury and now it’s a necessity simply due to the laws of supply and demand.\n",
    "\n",
    "This isn’t the only reason houses are so expensive, but it’s a big reason that people don’t like to talk about.\n",
    "\"\"\"\n",
    "# https://old.reddit.com/r/PoliticalCompassMemes/comments/x774os/conservative_you_say_sounds_fine_to_me/inbbz52/\n",
    "print(\"This is a %s comment\" %mapping[predict(ex_text_str, text_pipeline)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}